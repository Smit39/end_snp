{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:01.832172Z",
     "iopub.status.busy": "2023-10-03T06:29:01.830841Z",
     "iopub.status.idle": "2023-10-03T06:29:10.998868Z",
     "shell.execute_reply": "2023-10-03T06:29:10.997858Z",
     "shell.execute_reply.started": "2023-10-03T06:29:01.832134Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.001327Z",
     "iopub.status.busy": "2023-10-03T06:29:11.000711Z",
     "iopub.status.idle": "2023-10-03T06:29:11.027291Z",
     "shell.execute_reply": "2023-10-03T06:29:11.026342Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.001295Z"
    }
   },
   "outputs": [],
   "source": [
    "text=\"\"\n",
    "with open('/kaggle/input/nlp-specialization-data/Novel - Moby-Dick By Herman Melville.txt', 'r') as file:\n",
    "    text=file.readlines()\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.028909Z",
     "iopub.status.busy": "2023-10-03T06:29:11.028583Z",
     "iopub.status.idle": "2023-10-03T06:29:11.053381Z",
     "shell.execute_reply": "2023-10-03T06:29:11.052465Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.028877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER 1\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loomings.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22418</th>\n",
       "      <td>sheathed beaks.  On the second day, a sail dre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22419</th>\n",
       "      <td>picked me up at last.  It was the devious-crui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22420</th>\n",
       "      <td>her retracing search after her missing childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22421</th>\n",
       "      <td>orphan.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22422</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22423 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0                                            CHAPTER 1\\n\n",
       "1                                                     \\n\n",
       "2                                            Loomings.\\n\n",
       "3                                                     \\n\n",
       "4                                                     \\n\n",
       "...                                                  ...\n",
       "22418  sheathed beaks.  On the second day, a sail dre...\n",
       "22419  picked me up at last.  It was the devious-crui...\n",
       "22420  her retracing search after her missing childre...\n",
       "22421                                          orphan.\\n\n",
       "22422                                                 \\n\n",
       "\n",
       "[22423 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"text\":text})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.056301Z",
     "iopub.status.busy": "2023-10-03T06:29:11.055672Z",
     "iopub.status.idle": "2023-10-03T06:29:11.061046Z",
     "shell.execute_reply": "2023-10-03T06:29:11.060207Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.056267Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r'\\n+', \" \", text)\n",
    "    for i in string.punctuation:\n",
    "        text=text.replace(i, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.062927Z",
     "iopub.status.busy": "2023-10-03T06:29:11.062341Z",
     "iopub.status.idle": "2023-10-03T06:29:11.206223Z",
     "shell.execute_reply": "2023-10-03T06:29:11.205292Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.062899Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.207816Z",
     "iopub.status.busy": "2023-10-03T06:29:11.207531Z",
     "iopub.status.idle": "2023-10-03T06:29:11.268131Z",
     "shell.execute_reply": "2023-10-03T06:29:11.267243Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.207789Z"
    }
   },
   "outputs": [],
   "source": [
    "df=df[((df != ' ').all(1))].reset_index()\n",
    "df['n_words']=df['cleaned_text'].str.split(' ').apply(lambda x: len(x))\n",
    "df=df.loc[df['n_words']>7].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.269860Z",
     "iopub.status.busy": "2023-10-03T06:29:11.269538Z",
     "iopub.status.idle": "2023-10-03T06:29:11.282464Z",
     "shell.execute_reply": "2023-10-03T06:29:11.281570Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.269824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Call me Ishmael.  Some years ago--never mind h...</td>\n",
       "      <td>call me ishmael  some years agonever mind how ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>precisely--having little or no money in my pur...</td>\n",
       "      <td>preciselyhaving little or no money in my purse...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>particular to interest me on shore, I thought ...</td>\n",
       "      <td>particular to interest me on shore i thought i...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>little and see the watery part of the world.  ...</td>\n",
       "      <td>little and see the watery part of the world  i...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>driving off the spleen and regulating the circ...</td>\n",
       "      <td>driving off the spleen and regulating the circ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17555</th>\n",
       "      <td>19243</td>\n",
       "      <td>22416</td>\n",
       "      <td>soft and dirgelike main.  The unharming sharks...</td>\n",
       "      <td>soft and dirgelike main  the unharming sharks ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17556</th>\n",
       "      <td>19244</td>\n",
       "      <td>22417</td>\n",
       "      <td>with padlocks on their mouths; the savage sea-...</td>\n",
       "      <td>with padlocks on their mouths the savage seaha...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17557</th>\n",
       "      <td>19245</td>\n",
       "      <td>22418</td>\n",
       "      <td>sheathed beaks.  On the second day, a sail dre...</td>\n",
       "      <td>sheathed beaks  on the second day a sail drew ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17558</th>\n",
       "      <td>19246</td>\n",
       "      <td>22419</td>\n",
       "      <td>picked me up at last.  It was the devious-crui...</td>\n",
       "      <td>picked me up at last  it was the deviouscruisi...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>19247</td>\n",
       "      <td>22420</td>\n",
       "      <td>her retracing search after her missing childre...</td>\n",
       "      <td>her retracing search after her missing childre...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17560 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       level_0  index                                               text  \\\n",
       "0            2      5  Call me Ishmael.  Some years ago--never mind h...   \n",
       "1            3      6  precisely--having little or no money in my pur...   \n",
       "2            4      7  particular to interest me on shore, I thought ...   \n",
       "3            5      8  little and see the watery part of the world.  ...   \n",
       "4            6      9  driving off the spleen and regulating the circ...   \n",
       "...        ...    ...                                                ...   \n",
       "17555    19243  22416  soft and dirgelike main.  The unharming sharks...   \n",
       "17556    19244  22417  with padlocks on their mouths; the savage sea-...   \n",
       "17557    19245  22418  sheathed beaks.  On the second day, a sail dre...   \n",
       "17558    19246  22419  picked me up at last.  It was the devious-crui...   \n",
       "17559    19247  22420  her retracing search after her missing childre...   \n",
       "\n",
       "                                            cleaned_text  n_words  \n",
       "0      call me ishmael  some years agonever mind how ...       11  \n",
       "1      preciselyhaving little or no money in my purse...       11  \n",
       "2      particular to interest me on shore i thought i...       14  \n",
       "3      little and see the watery part of the world  i...       18  \n",
       "4      driving off the spleen and regulating the circ...       12  \n",
       "...                                                  ...      ...  \n",
       "17555  soft and dirgelike main  the unharming sharks ...       14  \n",
       "17556  with padlocks on their mouths the savage seaha...       11  \n",
       "17557  sheathed beaks  on the second day a sail drew ...       14  \n",
       "17558  picked me up at last  it was the deviouscruisi...       14  \n",
       "17559  her retracing search after her missing childre...       11  \n",
       "\n",
       "[17560 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.284337Z",
     "iopub.status.busy": "2023-10-03T06:29:11.283562Z",
     "iopub.status.idle": "2023-10-03T06:29:11.537490Z",
     "shell.execute_reply": "2023-10-03T06:29:11.536594Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.284305Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(oov_token='<oov>')\n",
    "tokenizer.fit_on_texts(df['cleaned_text'])\n",
    "total_words=len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.539216Z",
     "iopub.status.busy": "2023-10-03T06:29:11.538647Z",
     "iopub.status.idle": "2023-10-03T06:29:11.544728Z",
     "shell.execute_reply": "2023-10-03T06:29:11.543751Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.539183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 19116\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Words: {total_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:11.549120Z",
     "iopub.status.busy": "2023-10-03T06:29:11.548817Z",
     "iopub.status.idle": "2023-10-03T06:29:12.007535Z",
     "shell.execute_reply": "2023-10-03T06:29:12.006563Z",
     "shell.execute_reply.started": "2023-10-03T06:29:11.549097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sequences:  185497\n"
     ]
    }
   ],
   "source": [
    "input_sequences=[]\n",
    "\n",
    "for line in df['cleaned_text']:\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram=token_list[:i+1]\n",
    "        input_sequences.append(n_gram)\n",
    "        \n",
    "print(\"Total number of sequences: \", len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:12.009524Z",
     "iopub.status.busy": "2023-10-03T06:29:12.008970Z",
     "iopub.status.idle": "2023-10-03T06:29:12.413340Z",
     "shell.execute_reply": "2023-10-03T06:29:12.412373Z",
     "shell.execute_reply.started": "2023-10-03T06:29:12.009492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 18\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len=max([len(x) for x in input_sequences])\n",
    "print(\"Max sequence length:\", max_sequence_len)\n",
    "input_sequences=np.array(pad_sequences(input_sequences, padding='pre', maxlen=max_sequence_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:12.415068Z",
     "iopub.status.busy": "2023-10-03T06:29:12.414731Z",
     "iopub.status.idle": "2023-10-03T06:29:12.421539Z",
     "shell.execute_reply": "2023-10-03T06:29:12.420594Z",
     "shell.execute_reply.started": "2023-10-03T06:29:12.415038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0, 2003,  130,    2], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[45]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:12.423833Z",
     "iopub.status.busy": "2023-10-03T06:29:12.422859Z",
     "iopub.status.idle": "2023-10-03T06:29:12.433154Z",
     "shell.execute_reply": "2023-10-03T06:29:12.432238Z",
     "shell.execute_reply.started": "2023-10-03T06:29:12.423804Z"
    }
   },
   "outputs": [],
   "source": [
    "X, labels=input_sequences[:, :-1], input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:12.435243Z",
     "iopub.status.busy": "2023-10-03T06:29:12.434384Z",
     "iopub.status.idle": "2023-10-03T06:29:12.446435Z",
     "shell.execute_reply": "2023-10-03T06:29:12.445407Z",
     "shell.execute_reply.started": "2023-10-03T06:29:12.435213Z"
    }
   },
   "outputs": [],
   "source": [
    "ind=np.random.choice(X.shape[0], size=20000)\n",
    "X=X[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:12.448683Z",
     "iopub.status.busy": "2023-10-03T06:29:12.447654Z",
     "iopub.status.idle": "2023-10-03T06:29:12.456295Z",
     "shell.execute_reply": "2023-10-03T06:29:12.455403Z",
     "shell.execute_reply.started": "2023-10-03T06:29:12.448653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:12.458199Z",
     "iopub.status.busy": "2023-10-03T06:29:12.457631Z",
     "iopub.status.idle": "2023-10-03T06:29:13.958829Z",
     "shell.execute_reply": "2023-10-03T06:29:13.957912Z",
     "shell.execute_reply.started": "2023-10-03T06:29:12.458164Z"
    }
   },
   "outputs": [],
   "source": [
    "y=tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "y=y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:13.960590Z",
     "iopub.status.busy": "2023-10-03T06:29:13.960262Z",
     "iopub.status.idle": "2023-10-03T06:29:14.400092Z",
     "shell.execute_reply": "2023-10-03T06:29:14.399124Z",
     "shell.execute_reply.started": "2023-10-03T06:29:13.960560Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:14.401617Z",
     "iopub.status.busy": "2023-10-03T06:29:14.401299Z",
     "iopub.status.idle": "2023-10-03T06:29:18.622441Z",
     "shell.execute_reply": "2023-10-03T06:29:18.621468Z",
     "shell.execute_reply.started": "2023-10-03T06:29:14.401590Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model=Sequential()\n",
    "model.add(Embedding(total_words, 200, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(50)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "adam=Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:29:18.624456Z",
     "iopub.status.busy": "2023-10-03T06:29:18.623927Z",
     "iopub.status.idle": "2023-10-03T06:30:47.894300Z",
     "shell.execute_reply": "2023-10-03T06:30:47.893331Z",
     "shell.execute_reply.started": "2023-10-03T06:29:18.624426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 31s 94ms/step - loss: 8.0206 - accuracy: 0.0599 - val_loss: 7.6347 - val_accuracy: 0.0698\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 6.8683 - accuracy: 0.0694 - val_loss: 7.4933 - val_accuracy: 0.0678\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 6.4768 - accuracy: 0.0824 - val_loss: 7.4981 - val_accuracy: 0.0743\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 6.3255 - accuracy: 0.0903 - val_loss: 7.4655 - val_accuracy: 0.0808\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 6.5930 - accuracy: 0.1008 - val_loss: 7.7476 - val_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 6.0417 - accuracy: 0.1159 - val_loss: 7.8065 - val_accuracy: 0.0778\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 5.8372 - accuracy: 0.1251 - val_loss: 8.0428 - val_accuracy: 0.0813\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 5.6645 - accuracy: 0.1327 - val_loss: 8.1178 - val_accuracy: 0.0798\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 5.4845 - accuracy: 0.1393 - val_loss: 8.4361 - val_accuracy: 0.0835\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 5.2868 - accuracy: 0.1499 - val_loss: 8.2806 - val_accuracy: 0.0842\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-03T06:35:12.646467Z",
     "iopub.status.busy": "2023-10-03T06:35:12.645785Z",
     "iopub.status.idle": "2023-10-03T06:35:13.231707Z",
     "shell.execute_reply": "2023-10-03T06:35:13.230799Z",
     "shell.execute_reply.started": "2023-10-03T06:35:12.646435Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "picked me up at last the whale and have the whale and have have the\n"
     ]
    }
   ],
   "source": [
    "reversed_wi={value:key for key, value in tokenizer.word_index.items()}\n",
    "\n",
    "seed_text=\"picked me up at last\"\n",
    "next_words = 10\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list=tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], padding='pre', maxlen=max_sequence_len-1)\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word=reversed_wi[predicted[0]]\n",
    "    seed_text+=\" \"+output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is pretty visible that the model is not performing very well.\n",
    "This is due to the following reasons:\n",
    "- Better model training for more epochs\n",
    "- Improving model architexture to include more layers and more units per layers\n",
    "- Using transformer architecture over RNN family because Transformers better understands the contexts and is even quicker because of parallel processing.\n",
    "- Also, I had reduced the size of the input X because of out of memory issues so adding more rows can also be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
